# %%
import sys 

# to import library from a different folder. 
sys.path.insert(1, '/home/eva/git/analytics/scripts')

from util.snowflake_connection import get_connector
import pandas as pd 
from datetime import datetime 

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RepeatedStratifiedKFold, StratifiedKFold
from sklearn.metrics import accuracy_score, confusion_matrix,roc_curve, roc_auc_score, precision_score, recall_score, precision_recall_curve
from sklearn.metrics import f1_score
import numpy as np 
from scipy import stats
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

%matplotlib inline

def get_df(table_name:str) -> pd.DataFrame: 
    conn = get_connector() 
    
    qry = f'select * from {table_name}' 
    df = pd.read_sql(qry, conn)
    conn.close()

    df.columns = [c.lower() for c in df.columns]
    
    return df 

def make_dataset_backup():
    date_suffix = datetime.today().date().strftime('%Y%m%d')
    table_name = f'eva.model.leads_score_{date_suffix}'
    
    conn = get_connector() 
    
    print('Step: Drop table if exists.')

    rm_existing_table = f'drop table if exists {table_name};'
    conn.cursor().execute(rm_existing_table)
    conn.commit()
    
    print('Completed.')

    print('Step: Loading new table.')

    create_clause = f'''
    create table if not exists {table_name}
    as 
    '''
    qry = create_clause + open('leads_to_conversion.sql', 'r').read()
    
    conn.cursor().execute(qry)
    conn.commit()
    
    print('Completed.')

    qry = f'select * from {table_name}' 
    df = pd.read_sql(qry+' limit 10', conn)
    
    if not df.empty:
        print(f'table name: {table_name}')
        return table_name
    else:
        print('No data was queried. Returning empty DF')
        return None

def update_groups(df:pd.DataFrame, list_cols:list, threshold:int) -> pd.DataFrame:
    """
    Updating the cols in `list_cols` to `others` if the count of that group is 
    less than `threshold`. This is to prevent the data to be too sparse for prediction.  
    """
    df = df.copy()
    
    for col in list_cols: 
        cnter = df[col].value_counts() 
        keys = cnter[cnter.values<threshold].index.tolist()
        df[col] = df[col].replace(dict(zip(keys, ['others']*len(keys))))
        
    return df 
        
# %%

## workflow 
table_name = make_dataset_backup()


# %%
table_name = 'eva.model.leads_score_20230101'
df = get_df(table_name)

# %%

df['company_created_date'] = pd.to_datetime(df['company_created_date']).dt.date


df_test = df[df['company_created_date']>= datetime.strptime('2022-10-01', '%Y-%m-%d').date()]
df_train = df[df['company_created_date'] < datetime.strptime('2022-10-01', '%Y-%m-%d').date()]



# %%
df_test_desc = df_test.describe(include='all'
                                , datetime_is_numeric=True).transpose().iloc[:, :2]
df_test_desc.rename(columns={'count': 'count_ts',
                     'unique': 'unique_ts'}, inplace=True)
df_train_desc = df_train.describe(include='all'
                                  , datetime_is_numeric=True).transpose().iloc[:, :2]
df_train_desc.rename(columns={'count': 'count_tr',
                     'unique': 'unique_tr'}, inplace=True)

df_desc_comparison = pd.concat([df_test_desc ,df_train_desc]
                                , axis=1)


df_desc_comparison['diff']=df_desc_comparison['unique_ts'] - df_desc_comparison['unique_tr']
df_desc_comparison['%diff'] = df_desc_comparison['diff'] / df_desc_comparison['unique_tr']

# %%
mkt_cols = ['hdyhau', 'marketing_channel', 'mkt_medium', 'mkt_source']
df_desc_comparison[df_desc_comparison['diff']!=0].loc[mkt_cols]


# %%
print(df_desc_comparison[df_desc_comparison['diff']!=0].loc[mkt_cols])

# %%

# new values has existed in today's set;
# only care about the cols that are not in the model today 
# because it hasn't been captured. 
idx_to_check = df_desc_comparison.index[df_desc_comparison['%diff']>0].tolist()

# %%

idx_to_check = ['marketing_channel']



# %%
df_tr = df_train[idx_to_check].value_counts()
df_ts = df_test[idx_to_check].value_counts()



# %% 
type(df_tr)

# %%
for col in idx_to_check:
    df_tr = df_train.groupby(col, as_index=False)    

# %%
df_train.compare(df_test)

# %%
df_train.head()



# %% 
df2 = update_groups(df, ['industry_category', 'hdyhau', 'mkt_source'], 20)

# %%
df['is_converted'].value_counts(normalize=True) * 100

# %% 
df.columns

# %% 
c = sns.countplot(y='industry_category',
                  hue='is_converted_more_than_14days',
                  data=df2,
                  order=df2['industry_category'].value_counts().index)
c.set_title('Leads by Industry Category')
y_label = c.set_ylabel('Industry Category')


# %% 
df2.groupby(['industry_category'])['is_converted_0_to_14days'].count()


# %% 
cat_cols = ['industry_category', 'hdyhau', 'marketing_channel', 'mkt_medium', 'mkt_source',
            'has_opened_email_b4_conversion', 'has_opened_hot_emails', 'first_device_category'
            # , 'had_scheduled_ov_in_14days'
            ]

feature_cols = ['cummul_duration']

response_col = ['is_converted']

# %%
combs = {
    'base':{
        'cat_cols': ['industry_category', 'hdyhau', 'marketing_channel', 'mkt_medium', 'mkt_source',
            'has_opened_email_b4_conversion', 'has_opened_hot_emails', 'first_device_category'
            ]
        , 'feature_cols': ['cummul_duration']
        , 'response_col': ['is_converted']
    }
    , 'without_email': {
        'cat_cols': ['industry_category', 'hdyhau', 'marketing_channel', 'mkt_medium', 'mkt_source',
             'first_device_category'] 
        , 'feature_cols': ['cummul_duration']
        , 'response_col': ['is_converted']
        }
    , 'first_14days_conversion': {
        'cat_cols': ['industry_category', 'hdyhau', 'marketing_channel', 'mkt_medium', 'mkt_source',
            'has_opened_email_b4_conversion', 'has_opened_hot_emails', 'first_device_category'
            ] 
        , 'feature_cols': ['cummul_duration']
        , 'response_col': ['is_converted_0_to_14days']
        }
    , 'base+OV':{
        'cat_cols': ['industry_category', 'hdyhau', 'marketing_channel', 'mkt_medium', 'mkt_source',
            'has_opened_email_b4_conversion', 'has_opened_hot_emails', 'first_device_category', 
            'had_scheduled_ov_in_14days'
            ]
        , 'feature_cols': ['cummul_duration']
        , 'response_col': ['is_converted']
    }
}


# %%

# demo 
X = pd.get_dummies(data=df_train[cat_cols + feature_cols]
                   , columns=cat_cols)
y = df_train[response_col]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=16)

# %% 
df_train = update_groups(df_train, ['mkt_source'], 20)

# %%
for model, params in combs.items():
    mod = combs[model]
    cat_cols = mod['cat_cols']
    feature_cols = mod['feature_cols']
    response_col = mod['response_col']
    
    X = pd.get_dummies(data=df_train[cat_cols + feature_cols]
                      , columns=cat_cols)
    y = df_train[response_col]

    weight = df_train[response_col].value_counts(normalize=True).to_dict()
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=16)
    
    lg_w = LogisticRegression(random_state=16
                              , class_weight=weight
                              , solver='liblinear'
                              , penalty='l1')
    
    lg_w.fit(X_train, y_train.values.ravel())
    
    y_pred = lg_w.predict(X_test)
    
    print('Model: Weight Logistics Regression')
    print(f'Combo: {model}')
    print(f'Response Var: {response_col}')
    print(f'Accuracy Score: {accuracy_score(y_test,y_pred)}')
    print(f'Confusion Matrix: \n{confusion_matrix(y_test, y_pred)}')
    print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')
    print(f'Recall score: {recall_score(y_test,y_pred)}')
    print('='*30)



# %% 

# X_test = pd.get_dummies(data=df_test[cat_cols + feature_cols]
#                    , columns=cat_cols)
# y_test = df_test[response_col]

# features need to be fit into the model 
# report that shows new models

# %%
# define class weights
# w = {0:78, 1:22}
w = df_train['is_converted_0_to_14days'].value_counts(normalize=True).to_dict()
# define model
lg3 = LogisticRegression(random_state=13,
                         class_weight=w,
                         solver='liblinear')
# fit it
lg3.fit(X_train, y_train.values.ravel())
# test
y_pred = lg3.predict(X_test)
# performance
print(f'Accuracy Score: {accuracy_score(y_test,y_pred)}')
print(f'Confusion Matrix: \n{confusion_matrix(y_test, y_pred)}')
print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')
print(f'Recall score: {recall_score(y_test,y_pred)}')
# %%

y_pred_test = lg3.predict(X_test)
print(f'Accuracy Score: {accuracy_score(y_test,y_pred_test)}')
print(f'Confusion Matrix: \n{confusion_matrix(y_test, y_pred_test)}')
print(f'Area Under Curve: {roc_auc_score(y_test, y_pred_test)}')
print(f'Recall score: {recall_score(y_test,y_pred_test)}')